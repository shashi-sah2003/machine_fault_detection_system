{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashi-sah2003/machine_fault_detection_system/blob/main/machine_fault_detection_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Na8qA6hCaOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beced9f2-8381-4015-f3cb-551d29f6522a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "skT61TgxLBZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da4ca46-4191-4ffc-9aae-da225f0c8f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-Da2ciFDHj29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/id_00.zip"
      ],
      "metadata": {
        "id": "tqUBPHYeI4VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d senaca/mimii-pump-sound-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POt8YeQrC_P9",
        "outputId": "6103c69a-ae58-4331-a5c9-21659ad104e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-io matplotlib"
      ],
      "metadata": {
        "id": "Ly9mzZ8yDGmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b959f6d8-6498-4246-d2a1-30b925d880cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from glob import glob\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "from itertools import cycle\n",
        "\n",
        "sns.set_theme(style='white',palette=None)\n",
        "color_pal = plt.rcParams['axes.prop_cycle'].by_key()[\"color\"]\n",
        "color_cycle = cycle(plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"])\n"
      ],
      "metadata": {
        "id": "U7IhmMykDL7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q mimii-pump-sound-dataset.zip"
      ],
      "metadata": {
        "id": "wtwpvPZGDOPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17405a9-29fd-47cf-d51b-f6ee24cd66e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open mimii-pump-sound-dataset.zip, mimii-pump-sound-dataset.zip.zip or mimii-pump-sound-dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abnormal_audio_files = glob(\"/content/id_00/abnormal/*.wav\")\n",
        "\n",
        "normal_audio_files=glob(\"/content/id_00/normal/*.wav\")"
      ],
      "metadata": {
        "id": "bKX2r3stDPxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_audio_files=normal_audio_files[:500]\n",
        "\n",
        "print(len(normal_audio_files))\n",
        "print(len(abnormal_audio_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GWvczt1DYSk",
        "outputId": "d2fcf532-49c6-4dbe-874e-9dce3b72b4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Wavelet\n",
        "import pywt\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# Define the wavelet parameters\n",
        "wavelet = 'db4'  # Choose a specific wavelet (e.g., Daubechies 4)\n",
        "level = 5  # Level of decomposition\n",
        "\n",
        "normal_audio_wavelet = []\n",
        "for i in range(len(normal_audio_files)):\n",
        "    normal_y_wav, sr = librosa.load(normal_audio_files[i])\n",
        "    coeffs = pywt.wavedec(normal_y_wav, wavelet, level=level)\n",
        "    feature = np.concatenate(coeffs)\n",
        "    normal_audio_wavelet.append(feature)\n",
        "normal_audio_wavelet = np.array(normal_audio_wavelet)\n",
        "print(normal_audio_wavelet.shape)\n",
        "#print(normal_audio_wavelet)\n",
        "\n",
        "abnormal_audio_wavelet = []\n",
        "for i in range(len(abnormal_audio_files)):\n",
        "    abnormal_y_wav, sr = librosa.load(abnormal_audio_files[i])\n",
        "    coeffs = pywt.wavedec(abnormal_y_wav, wavelet, level=level)\n",
        "    feature = np.concatenate(coeffs)\n",
        "    abnormal_audio_wavelet.append(feature)\n",
        "abnormal_audio_wavelet = np.array(abnormal_audio_wavelet)\n",
        "print(abnormal_audio_wavelet.shape)\n",
        "#print(abnormal_audio_wavelet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "javFZBd7Dd_b",
        "outputId": "698a10c5-d645-48ad-b586-6e554b840293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(250, 220532)\n",
            "(143, 220532)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kurtosis\n",
        "import numpy as np\n",
        "from scipy.stats import kurtosis\n",
        "normal_audio_wavelet_kurtosis = []\n",
        "for i in range(normal_audio_wavelet.shape[0]):\n",
        "    #print(normal_audio_wavelet[i].shape)\n",
        "    S = librosa.stft(normal_audio_wavelet[i])\n",
        "    sk = kurtosis(np.abs(S), axis=1)\n",
        "\n",
        "    # sk = kurtosis(normal_audio_wavelet[i])\n",
        "    #print(sk)\n",
        "    normal_audio_wavelet_kurtosis.append(sk)\n",
        "\n",
        "abnormal_audio_wavelet_kurtosis = []\n",
        "\n",
        "for i in range(abnormal_audio_wavelet.shape[0]):\n",
        "\n",
        "\n",
        "    S = librosa.stft(abnormal_audio_wavelet[i])\n",
        "    sk = kurtosis(np.abs(S), axis=1)\n",
        "\n",
        "    # sk = kurtosis(normal_audio_wavelet[i])\n",
        "    #print(sk)\n",
        "    abnormal_audio_wavelet_kurtosis.append(sk)\n",
        "print(normal_audio_wavelet)\n",
        "#print(abnormal_audio_wavelet.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qr4MJIDhDw58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e534bdb3-bcec-420a-9870-179ea6944b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4.60983105e-02  4.74286564e-02  4.69540805e-02 ...  1.25267927e-03\n",
            "   2.09145271e-03 -2.33352184e-03]\n",
            " [ 8.57375860e-02  8.68345574e-02  8.69859308e-02 ...  2.93611258e-04\n",
            "  -8.34901875e-05  5.48280543e-04]\n",
            " [-7.67729729e-02 -7.63556808e-02 -7.82789290e-02 ... -5.40435780e-04\n",
            "  -1.02616963e-03  6.61987870e-04]\n",
            " ...\n",
            " [ 4.96645272e-02  4.82572466e-02  4.91190776e-02 ...  6.31883740e-04\n",
            "   1.33804872e-03 -9.57545533e-04]\n",
            " [ 1.37727842e-01  1.40397668e-01  1.39134958e-01 ... -9.82671510e-04\n",
            "  -1.72193279e-03  1.19647605e-03]\n",
            " [ 9.84938070e-02  9.63670984e-02  9.73304808e-02 ... -1.09198656e-04\n",
            "  -3.05578695e-04  6.15366094e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_audio_wavelet_kurtosis= np.array(normal_audio_wavelet_kurtosis)\n",
        "print(normal_audio_wavelet_kurtosis.shape)\n",
        "abnormal_audio_wavelet_kurtosis= np.array(abnormal_audio_wavelet_kurtosis)\n",
        "print(abnormal_audio_wavelet_kurtosis.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzZ3jAVuD0Ut",
        "outputId": "7afa51f1-8057-4b6b-ea96-f07f8ac89f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(250, 1025)\n",
            "(143, 1025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Spectral centroid\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "normal_audio_wavelet_centroid = []\n",
        "for i in range(len(normal_audio_wavelet)):\n",
        "    S = librosa.stft(normal_audio_wavelet[i])\n",
        "    centroid = librosa.feature.spectral_centroid(S=np.abs(S))\n",
        "    normal_audio_wavelet_centroid.append(centroid)\n",
        "normal_audio_wavelet_centroid = np.array(normal_audio_wavelet_centroid)\n",
        "print(normal_audio_wavelet_centroid.shape)\n",
        "print(normal_audio_wavelet_centroid)\n",
        "\n",
        "abnormal_audio_wavelet_centroid = []\n",
        "for i in range(len(abnormal_audio_wavelet)):\n",
        "    S = librosa.stft(abnormal_audio_wavelet[i])\n",
        "    centroid = librosa.feature.spectral_centroid(S=np.abs(S))\n",
        "    abnormal_audio_wavelet_centroid.append(centroid)\n",
        "abnormal_audio_wavelet_centroid = np.array(abnormal_audio_wavelet_centroid)\n",
        "print(abnormal_audio_wavelet_centroid.shape)\n",
        "print(abnormal_audio_wavelet_centroid)\n"
      ],
      "metadata": {
        "id": "HgtcdSLTwSpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_audio_wavelet_centroid = np.reshape(normal_audio_wavelet_centroid, (normal_audio_wavelet_centroid.shape[0], -1))\n",
        "abnormal_audio_wavelet_centroid = np.reshape(abnormal_audio_wavelet_centroid, (abnormal_audio_wavelet_centroid.shape[0], -1))\n",
        "print(normal_audio_wavelet_centroid.shape)"
      ],
      "metadata": {
        "id": "jfxWT7A8xdFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72735986-e24a-466c-eee4-cc779247f4e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(250, 431)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ZERO CROSSING RATE\n",
        "\n",
        "normal_audio_wavelet_zcr = []\n",
        "for i in range(len(normal_audio_wavelet)):\n",
        "    # normal_y_zcr, sr = librosa.load(normal_audio_wavelet[i])\n",
        "    zcr = librosa.feature.zero_crossing_rate(normal_audio_wavelet[i])\n",
        "    normal_audio_wavelet_zcr.append(zcr)\n",
        "normal_audio_wavelet_zcr = np.array(normal_audio_wavelet_zcr)\n",
        "print(normal_audio_wavelet_zcr.shape)\n",
        "#print(normal_audio_wavelet_zcr)\n",
        "\n",
        "abnormal_audio_wavelet_zcr = []\n",
        "for i in range(len(abnormal_audio_wavelet)):\n",
        "    #y, sr = librosa.load(abnormal_audio_wavelet[i])\n",
        "    zcr = librosa.feature.zero_crossing_rate(abnormal_audio_wavelet[i])\n",
        "    abnormal_audio_wavelet_zcr.append(zcr)\n",
        "abnormal_audio_wavelet_zcr = np.array(abnormal_audio_wavelet_zcr)\n",
        "print(abnormal_audio_wavelet_zcr.shape)\n",
        "print(abnormal_audio_wavelet_zcr)"
      ],
      "metadata": {
        "id": "eV8faDB4EQfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MEL Spectrogram\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "\n",
        "normal_wav_audio_melspec = []\n",
        "for audio_data in normal_audio_wavelet:\n",
        "    melspec = librosa.feature.melspectrogram(y=audio_data, sr=sr)\n",
        "    normal_wav_audio_melspec.append(melspec)\n",
        "normal_wav_audio_melspec = np.array(normal_wav_audio_melspec)\n",
        "#print(abnormal_wav_audio_melspec.shape)\n",
        "print(normal_wav_audio_melspec)\n",
        "\n",
        "abnormal_wav_audio_melspec = []\n",
        "for audio_data in abnormal_audio_wavelet:\n",
        "    melspec = librosa.feature.melspectrogram(y=audio_data, sr=sr)\n",
        "    abnormal_wav_audio_melspec.append(melspec)\n",
        "abnormal_wav_audio_melspec = np.array(abnormal_wav_audio_melspec)\n",
        "#print(abnormal_wav_audio_melspec.shape)\n",
        "print(abnormal_wav_audio_melspec)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "evb7bgtpW29O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_wav_audio_melspec = np.reshape(normal_wav_audio_melspec, (normal_wav_audio_melspec.shape[0], -1))\n",
        "abnormal_wav_audio_melspec = np.reshape(abnormal_wav_audio_melspec, (abnormal_wav_audio_melspec.shape[0], -1))"
      ],
      "metadata": {
        "id": "fxsOhIw9K3RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j_6DsLJFr6Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(abnormal_wav_audio_melspec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biAKMYT3LT-Q",
        "outputId": "b54fc2fe-9b1b-42be-e954-61da6b0ca6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(143, 55168)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_contac_all=[]\n",
        "for i in range(len(normal_audio_wavelet_kurtosis)):\n",
        "  contac= np.concatenate((normal_audio_wavelet_kurtosis[i],normal_audio_wavelet_zcr[i][0],normal_wav_audio_melspec[i],normal_audio_wavelet_centroid[i]))\n",
        "  normal_contac_all.append(contac)\n",
        "normal_contac_all=np.array(normal_contac_all)\n",
        "\n",
        "abnormal_contac_all=[]\n",
        "for i in range(len(abnormal_audio_wavelet_kurtosis)):\n",
        "  ab_contac= np.concatenate((abnormal_audio_wavelet_kurtosis[i],abnormal_audio_wavelet_zcr[i][0],abnormal_wav_audio_melspec[i],abnormal_audio_wavelet_centroid[i]))\n",
        "  abnormal_contac_all.append(ab_contac)\n",
        "abnormal_contac_all=np.array(abnormal_contac_all)"
      ],
      "metadata": {
        "id": "ihKqt8gzFj-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normal_contac_all.shape)\n",
        "print(abnormal_contac_all.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlTWcz5mGMS9",
        "outputId": "a6b4e251-d416-47f5-8ba7-bde0c2ab516b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(250, 57055)\n",
            "(143, 57055)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1=np.zeros(normal_contac_all.shape[0])\n",
        "y2=np.ones(abnormal_contac_all.shape[0])\n",
        "y_features=np.concatenate((y1, y2))\n",
        "# print(y_train)\n",
        "\n",
        "X_features=np.concatenate((normal_contac_all,abnormal_contac_all ))\n",
        "print(y_features.shape)\n",
        "print(X_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTjpMAVeGgc_",
        "outputId": "dc698de6-8b21-46aa-9f00-867e3b2905e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(393,)\n",
            "(393, 57055)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a NumPy array\n",
        "data = X_features\n",
        "labels=y_features\n",
        "\n",
        "# Create a NumPy array of labels\n",
        "# labels = np.array([0, 1, 0, 1])\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Shuffle the indices\n",
        "indices = np.random.permutation(len(data))\n",
        "\n",
        "# Shuffle the data and labels based on the shuffled indices\n",
        "shuffled_data = data[indices]\n",
        "shuffled_labels = labels[indices]\n",
        "\n",
        "# Set the desired ratio for train-test split\n",
        "train_ratio = 0.75\n",
        "\n",
        "# Calculate the split index\n",
        "split_index = int(train_ratio * len(data))\n",
        "\n",
        "# Split the data and labels into train and test sets\n",
        "train_data_features = shuffled_data[:split_index]\n",
        "train_labels_features = shuffled_labels[:split_index]\n",
        "test_data_features = shuffled_data[split_index:]\n",
        "test_labels_features = shuffled_labels[split_index:]\n",
        "\n",
        "# Print the train and test sets\n",
        "print(\"Training Data:\")\n",
        "print(train_data_features)\n",
        "print(\"Training Labels:\")\n",
        "print(train_labels_features)\n",
        "print(\"Testing Data:\")\n",
        "print(test_data_features)\n",
        "print(\"Testing Labels:\")\n",
        "print(test_labels_features)"
      ],
      "metadata": {
        "id": "1SN2lZ2QGoez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f681b9-5fe7-4860-8ea5-92970467d254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "[[7.88859844e+00 6.47374821e+00 1.07415028e+01 ... 8.35131946e+03\n",
            "  8.30612401e+03 8.29806426e+03]\n",
            " [1.17017006e+02 1.14996292e+02 1.17644562e+02 ... 8.31501274e+03\n",
            "  8.25447386e+03 8.29933405e+03]\n",
            " [1.94597683e+01 1.33880196e+01 1.63868198e+01 ... 8.36283697e+03\n",
            "  8.27546013e+03 8.22311250e+03]\n",
            " ...\n",
            " [4.84406128e+01 3.80999489e+01 1.94259777e+01 ... 8.21669038e+03\n",
            "  8.20756335e+03 8.15971367e+03]\n",
            " [4.71737061e+01 3.56539917e+01 3.01593361e+01 ... 8.16043621e+03\n",
            "  8.27095413e+03 8.22775959e+03]\n",
            " [5.80856991e+00 3.52005053e+00 5.32268524e+00 ... 8.41193798e+03\n",
            "  8.40540169e+03 8.40327018e+03]]\n",
            "Training Labels:\n",
            "[0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1.\n",
            " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 1. 0.]\n",
            "Testing Data:\n",
            "[[1.18324135e+02 5.67642326e+01 4.44296532e+01 ... 8.26964104e+03\n",
            "  8.34497041e+03 8.21019007e+03]\n",
            " [4.49261551e+01 2.89783401e+01 1.75999889e+01 ... 8.23903617e+03\n",
            "  8.17908793e+03 8.16052020e+03]\n",
            " [1.15105963e+01 1.54948864e+01 1.34982548e+01 ... 8.48996472e+03\n",
            "  8.56736758e+03 8.55945648e+03]\n",
            " ...\n",
            " [4.32002144e+01 4.32456017e+01 5.08811493e+01 ... 8.12321044e+03\n",
            "  8.09199715e+03 8.08436070e+03]\n",
            " [1.50992794e+01 1.49716797e+01 1.34456615e+01 ... 8.23372274e+03\n",
            "  8.11435634e+03 7.74879713e+03]\n",
            " [8.18050385e+00 5.10225582e+00 8.60819435e+00 ... 8.40881581e+03\n",
            "  8.42943620e+03 8.41537448e+03]]\n",
            "Testing Labels:\n",
            "[1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
            " 1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "#np.random.seed(42)\n",
        "\n",
        "# Split the data and labels into train and test sets\n",
        "train_data_features, test_data_features, train_labels_features, test_labels_features = train_test_split(\n",
        "    data, labels, train_size=0.75, random_state=0)\n",
        "\n",
        "# Print the train and test sets\n",
        "print(\"Training Data:\")\n",
        "print(train_data_features)\n",
        "print(\"Training Labels:\")\n",
        "print(train_labels_features)\n",
        "print(\"Testing Data:\")\n",
        "print(test_data_features)\n",
        "print(\"Testing Labels:\")\n",
        "print(test_labels_features)\n"
      ],
      "metadata": {
        "id": "RLJ2EwAohAjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data = train_data_features\n",
        "train_labels = train_labels_features\n",
        "#test_data = test_data_features\n",
        "test_labels = test_labels_features"
      ],
      "metadata": {
        "id": "7AJ70JUIEM6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "train_data = scaler.fit_transform(train_data_features)\n",
        "test_data = scaler.transform(test_data_features)"
      ],
      "metadata": {
        "id": "Hf8m8RBeEMq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensemble model of Random forest and XGboost\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "random_forest = RandomForestClassifier()\n",
        "xgboost = XGBClassifier()\n",
        "\n",
        "ensemble_model = VotingClassifier(estimators=[('rf', random_forest), ('xgb', xgboost)], voting='hard')\n",
        "ensemble_model.fit(train_data, train_labels)\n",
        "ensemble_model.predict(test_data)\n",
        "ensemble_model.score(test_data, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrdSt1vbjiN2",
        "outputId": "bd9a5051-82f2-4a1b-fdcb-4c232a3b2e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9393939393939394"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Assuming you have already trained and tested the ensemble_model\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, y_pred)\n",
        "\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-5N5Ezcp8Rq",
        "outputId": "7debb973-e624-450a-bc9d-de1f5b599a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.9142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensemble model of RFC and SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "random_forest = RandomForestClassifier()\n",
        "svc = SVC(probability=True)  # Set probability=True for soft voting\n",
        "\n",
        "ensemble_model = VotingClassifier(estimators=[('rf', random_forest), ('svc', svc)], voting='soft')\n",
        "\n",
        "ensemble_model.fit(train_data, train_labels)\n",
        "ensemble_model.predict(test_data)\n",
        "ensemble_model.score(test_data, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGHSX62Sozv8",
        "outputId": "820272d9-cd70-470e-85c6-30e22f83b16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9292929292929293"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Assuming you have already trained and tested the ensemble_model\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_model.predict(test_data_scaled)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, y_pred)\n",
        "\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHp8QYLxqqbU",
        "outputId": "004c5c00-6ace-4ace-af6a-f770ae8d1270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.898550724637681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensemble model of SVC and XGboost\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "svc = SVC(probability=True)  # Set probability=True for soft voting\n",
        "xgboost = XGBClassifier()\n",
        "\n",
        "ensemble_model = VotingClassifier(estimators=[('svc', svc), ('xgb', xgboost)], voting='soft')\n",
        "\n",
        "ensemble_model.fit(train_data, train_labels)\n",
        "ensemble_model.predict(test_data)\n",
        "ensemble_model.score(test_data, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5VsOKPusM_c",
        "outputId": "23bc31fa-d3ce-4a57-c61c-67867c567ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9595959595959596"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Assuming you have already trained and tested the ensemble_model\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = ensemble_model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, y_pred)\n",
        "\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvRDb0Lft88Y",
        "outputId": "bdd659d1-2137-442a-dbcc-1b3f2c613659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.9459459459459458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# # Generate dummy data\n",
        "# data = np.random.random((1000, 10))  # Replace with your own data\n",
        "# labels = np.random.randint(2, size=(1000, 1))  # Replace with your own labels\n",
        "\n",
        "# Split data into training and testing sets\n",
        "#train_data = train_data_features\n",
        "train_labels = train_labels_features\n",
        "#test_data = test_data_features\n",
        "test_labels = test_labels_features\n",
        "\n",
        "# Build the ANN model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=train_data.shape[1], activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Set the learning rate\n",
        "# learning_rate = 0.01\n",
        "# optimizer = Adam(learning_rate=learning_rate)\n",
        "# Train the model\n",
        "model.fit(train_data, train_labels, epochs=50, batch_size=16, verbose=1)\n",
        "# model.fit(train_data, train_labels, verbose=1)\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_data, test_labels, verbose=1)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "rf8emypKGr3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Assuming you have the predictions for the test set\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, predictions)\n",
        "\n",
        "print('F1 Score:', f1)\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "# Assuming you have the predictions for the test set\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, predictions)\n",
        "\n",
        "print('F1 Score:', f1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "mNoLsipWykWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# # Split data into training and testing sets\n",
        "# train_data = train_data_features\n",
        "# train_labels = train_labels_features\n",
        "# test_data = test_data_features\n",
        "# test_labels = test_labels_features\n",
        "\n",
        "# # Build the SVM model\n",
        "# model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(train_data, train_labels)\n",
        "\n",
        "# # Evaluate the model\n",
        "# accuracy = model.score(test_data, test_labels)\n",
        "# print('Test Accuracy:', accuracy)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Normalize the data\n",
        "# scaler = StandardScaler()\n",
        "# train_data_scaled = scaler.fit_transform(train_data_features)\n",
        "# test_data_scaled = scaler.transform(test_data_features)\n",
        "\n",
        "# Build the SVM model\n",
        "model = SVC()\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {'C': [0.1, 1, 10],\n",
        "              'gamma': ['scale', 'auto'],\n",
        "              'kernel': ['linear', 'rbf']}\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(train_data, train_labels_features)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Perform cross-validation to evaluate the model\n",
        "cross_val_scores = cross_val_score(best_model, train_data, train_labels_features, cv=5)\n",
        "mean_cross_val_accuracy = cross_val_scores.mean()\n",
        "\n",
        "# Train the best model on the entire training data\n",
        "best_model.fit(train_data, train_labels_features)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_accuracy = best_model.score(test_data, test_labels_features)\n",
        "\n",
        "print('Cross-Validation Accuracy:', mean_cross_val_accuracy)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "print('Best Model:', best_model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnwxGIB2GyrY",
        "outputId": "b041b7aa-a137-4071-9293-30932cfdc2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy: 0.8265341905318527\n",
            "Test Accuracy: 0.8383838383838383\n",
            "Best Model: SVC(C=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Assuming you have the predictions for the test set\n",
        "predictions = best_model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, predictions)\n",
        "\n",
        "print('F1 Score:', f1)\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "# Assuming you have the predictions for the test set\n",
        "predictions = best_model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, predictions)\n",
        "\n",
        "print('F1 Score:', f1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgEwaPWTy67i",
        "outputId": "2d2500d3-a374-4203-d25d-912c63a62760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.7894736842105263\n",
            "F1 Score: 0.7894736842105263\n",
            "Confusion Matrix:\n",
            "[[53  8]\n",
            " [ 8 30]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# # Generate dummy data\n",
        "# data = np.random.random((1000, 10))  # Replace with your own data\n",
        "# labels = np.random.randint(2, size=(1000, 1))  # Replace with your own labels\n",
        "\n",
        "# # Split data into training and testing sets\n",
        "train_data = train_data_features\n",
        "train_labels = train_labels_features\n",
        "test_data = test_data_features\n",
        "test_labels = test_labels_features\n",
        "\n",
        "# Reshape data to fit LSTM input shape\n",
        "train_data = np.reshape(train_data, (train_data.shape[0], 1, train_data.shape[1]))\n",
        "test_data = np.reshape(test_data, (test_data.shape[0], 1, test_data.shape[1]))\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(1, train_data.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_data, train_labels, epochs=25, batch_size=16, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_data, test_labels, verbose=1)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "kEzdoYUPJSHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Assuming you have the predictions for the test set\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, predictions)\n",
        "\n",
        "print('F1 Score:', f1)\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "# Assuming you have the predictions for the test set\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, predictions)\n",
        "\n",
        "print('F1 Score:', f1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "1oOoK3tnzEjI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "7a53aa41-8baa-45ae-acb8-0f77e4ce404d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 14ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-cc335955a383>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate the F1 score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1 Score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \"\"\"\n\u001b[0;32m-> 1146\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \"\"\"\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1288\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split data into training and testing sets\n",
        "#train_data = train_data_features\n",
        "train_labels = train_labels_features\n",
        "#test_data = test_data_features\n",
        "test_labels = test_labels_features\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "model = RandomForestClassifier(n_estimators=60)\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_data, train_labels)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print('Test Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "id": "-LCIwpgKJv88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f21e02-6702-403d-badc-6ba519be5b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9393939393939394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "# Assuming you have the predictions for the test set\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, predictions)\n",
        "\n",
        "print('F1 Score:', f1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HMn9jv2zG3T",
        "outputId": "0ff32318-0c7e-4414-8ddc-ff02364ee98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.9142857142857143\n",
            "Confusion Matrix:\n",
            "[[61  0]\n",
            " [ 6 32]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have the training and testing data and labels\n",
        "# train_data = train_data_features\n",
        "train_labels = train_labels_features\n",
        "# test_data = test_data_features\n",
        "test_labels = test_labels_features\n",
        "\n",
        "# Create the XGBoost Classifier model\n",
        "model = xgb.XGBClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_data, train_labels)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print('Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RoZ5_WotJ13",
        "outputId": "a9ac990c-bf1f-4da8-db60-11fa491e24e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9595959595959596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Assuming you have the predictions for the test set\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(test_labels, predictions)\n",
        "\n",
        "print('F1 Score:', f1)\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(test_labels, predictions)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3L4_TuF0ngh",
        "outputId": "f1c6df1e-4dcb-494d-c6ad-9ae954991f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.9473684210526315\n",
            "Confusion Matrix:\n",
            "[[59  2]\n",
            " [ 2 36]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JT9j1KOe6BAM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}